{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Автор материала: Юрий Исаков и Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейные модели классификации и регрессии\n",
    "## <center>  Практика. Идентификация пользователя с помощью логистической регрессии\n",
    "\n",
    "Тут мы воспроизведем парочку бенчмарков нашего соревнования и вдохновимся побить третий бенчмарк, а также остальных участников. Веб-формы для отправки ответов тут не будет, ориентир – [leaderboard](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/leaderboard) соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\bgdnv\\appdata\\roaming\\python\\python36\\site-packages (4.28.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и преобразование данных\n",
    "Зарегистрируйтесь на [Kaggle](www.kaggle.com), если вы не сделали этого раньше, зайдите на [страницу](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования и скачайте данные. Первым делом загрузим обучающую и тестовую выборки и посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('data/train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('data/test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>2014-10-04 11:19:53</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2014-10-04 11:19:53</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>321.0</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>6730.0</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>44582.0</td>\n",
       "      <td>2014-10-04 11:20:00</td>\n",
       "      <td>15336.0</td>\n",
       "      <td>2014-10-04 11:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>782</td>\n",
       "      <td>2014-07-03 11:00:28</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:00:53</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:00:58</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:06</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:09</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:10</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:23</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:29</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:30</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-07-03 11:01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>2014-12-05 15:55:12</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:55:13</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:55:14</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:56:15</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:56:16</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:56:17</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:56:18</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014-12-05 15:56:19</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>2014-12-05 15:56:33</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>2014-12-05 15:56:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023</td>\n",
       "      <td>2014-11-04 10:03:19</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2014-11-04 10:03:19</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2014-11-04 10:03:20</td>\n",
       "      <td>222.0</td>\n",
       "      <td>2014-11-04 10:03:21</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2014-11-04 10:03:21</td>\n",
       "      <td>3374.0</td>\n",
       "      <td>2014-11-04 10:03:22</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2014-11-04 10:03:22</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2014-11-04 10:03:22</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2014-11-04 10:03:23</td>\n",
       "      <td>3374.0</td>\n",
       "      <td>2014-11-04 10:03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>301</td>\n",
       "      <td>2014-05-16 15:05:31</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2014-05-16 15:05:32</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2014-05-16 15:05:33</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2014-05-16 15:05:39</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2014-05-16 15:05:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1   site2               time2  site3  \\\n",
       "session_id                                                                 \n",
       "1              29 2014-10-04 11:19:53    35.0 2014-10-04 11:19:53   22.0   \n",
       "2             782 2014-07-03 11:00:28   782.0 2014-07-03 11:00:53  782.0   \n",
       "3              55 2014-12-05 15:55:12    55.0 2014-12-05 15:55:13   55.0   \n",
       "4            1023 2014-11-04 10:03:19  1022.0 2014-11-04 10:03:19   50.0   \n",
       "5             301 2014-05-16 15:05:31   301.0 2014-05-16 15:05:32  301.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "1          2014-10-04 11:19:54  321.0 2014-10-04 11:19:54   23.0   \n",
       "2          2014-07-03 11:00:58  782.0 2014-07-03 11:01:06  782.0   \n",
       "3          2014-12-05 15:55:14   55.0 2014-12-05 15:56:15   55.0   \n",
       "4          2014-11-04 10:03:20  222.0 2014-11-04 10:03:21  202.0   \n",
       "5          2014-05-16 15:05:33   66.0 2014-05-16 15:05:39   67.0   \n",
       "\n",
       "                         time5   site6               time6   site7  \\\n",
       "session_id                                                           \n",
       "1          2014-10-04 11:19:54  2211.0 2014-10-04 11:19:54  6730.0   \n",
       "2          2014-07-03 11:01:09   782.0 2014-07-03 11:01:10   782.0   \n",
       "3          2014-12-05 15:56:16    55.0 2014-12-05 15:56:17    55.0   \n",
       "4          2014-11-04 10:03:21  3374.0 2014-11-04 10:03:22    50.0   \n",
       "5          2014-05-16 15:05:40    69.0 2014-05-16 15:05:40    70.0   \n",
       "\n",
       "                         time7  site8               time8    site9  \\\n",
       "session_id                                                           \n",
       "1          2014-10-04 11:19:54   21.0 2014-10-04 11:19:54  44582.0   \n",
       "2          2014-07-03 11:01:23  782.0 2014-07-03 11:01:29    782.0   \n",
       "3          2014-12-05 15:56:18   55.0 2014-12-05 15:56:19   1445.0   \n",
       "4          2014-11-04 10:03:22   48.0 2014-11-04 10:03:22     48.0   \n",
       "5          2014-05-16 15:05:40   68.0 2014-05-16 15:05:40     71.0   \n",
       "\n",
       "                         time9   site10              time10  \n",
       "session_id                                                   \n",
       "1          2014-10-04 11:20:00  15336.0 2014-10-04 11:20:00  \n",
       "2          2014-07-03 11:01:30    782.0 2014-07-03 11:01:53  \n",
       "3          2014-12-05 15:56:33   1445.0 2014-12-05 15:56:36  \n",
       "4          2014-11-04 10:03:23   3374.0 2014-11-04 10:03:23  \n",
       "5          2014-05-16 15:05:40    167.0 2014-05-16 15:05:44  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке содержатся следующие признаки:\n",
    "    - site1 – индекс первого посещенного сайта в сессии\n",
    "    - time1 – время посещения первого сайта в сессии\n",
    "    - ...\n",
    "    - site10 – индекс 10-го посещенного сайта в сессии\n",
    "    - time10 – время посещения 10-го сайта в сессии\n",
    "    - target – целевая переменная, 1 для сессий Элис, 0 для сессий других пользователей\n",
    "    \n",
    "Сессии пользователей выделены таким образом, что они не могут быть длиннее получаса или 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд либо когда сессия заняла по времени более 30 минут.\n",
    "\n",
    "В таблице встречаются пропущенные значения, это значит, что сессия состоит менее, чем из 10 сайтов. Заменим пропущенные значения нулями и приведем признаки к целому типу. Также загрузим словарь сайтов и посмотрим, как он выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n",
    "                          index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    train_df['site%s' % i] = train_df['site%s' % i].map(sites_dict_df['site'])\n",
    "    test_df['site%s' % i] = test_df['site%s' % i].map(sites_dict_df['site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>javadl-esd-secure.oracle.com</td>\n",
       "      <td>www.caucho.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>www.caucho.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>master.dl.sourceforge.net</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site1                          site2  \\\n",
       "session_id                                                                   \n",
       "21669       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                        www.apache.org                 www.apache.org   \n",
       "114021                      www.webtide.com            download.oracle.com   \n",
       "146670                   public.dhe.ibm.com                   jope.ow2.org   \n",
       "\n",
       "                                      site3                          site4  \\\n",
       "session_id                                                                   \n",
       "21669                                   NaN                            NaN   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                  download.eclipse.org                 www.apache.org   \n",
       "114021                       www.caucho.com            download.oracle.com   \n",
       "146670                  download.oracle.com             public.dhe.ibm.com   \n",
       "\n",
       "                      site5                      site6                site7  \\\n",
       "session_id                                                                    \n",
       "21669                   NaN                        NaN                  NaN   \n",
       "54843                   NaN                        NaN                  NaN   \n",
       "77292        www.apache.org            www.webtide.com  download.oracle.com   \n",
       "114021      www.webtide.com             www.apache.org   public.dhe.ibm.com   \n",
       "146670         jope.ow2.org  master.dl.sourceforge.net       www.apache.org   \n",
       "\n",
       "                                   site8           site9              site10  \n",
       "session_id                                                                    \n",
       "21669                                NaN             NaN                 NaN  \n",
       "54843                                NaN             NaN                 NaN  \n",
       "77292       javadl-esd-secure.oracle.com  www.caucho.com      www.apache.org  \n",
       "114021                   www.webtide.com  www.apache.org      www.apache.org  \n",
       "146670              download.eclipse.org  www.apache.org  public.dhe.ibm.com  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[sites].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>2014-10-04 11:19:53</td>\n",
       "      <td>s-static.ak.facebook.com</td>\n",
       "      <td>2014-10-04 11:19:53</td>\n",
       "      <td>apis.google.com</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>c1.adform.net</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>www.google.com</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>mpp2.vindicosuite.com</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>api.nanigans.com</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>www.google.fr</td>\n",
       "      <td>2014-10-04 11:19:54</td>\n",
       "      <td>secure.vistaprint.fr</td>\n",
       "      <td>2014-10-04 11:20:00</td>\n",
       "      <td>www.vistaprint.fr</td>\n",
       "      <td>2014-10-04 11:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:00:28</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:00:53</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:00:58</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:06</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:09</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:10</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:23</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:29</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:30</td>\n",
       "      <td>annotathon.org</td>\n",
       "      <td>2014-07-03 11:01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:55:12</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:55:13</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:55:14</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:56:15</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:56:16</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:56:17</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:56:18</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>2014-12-05 15:56:19</td>\n",
       "      <td>o2i.univ-bpclermont.fr</td>\n",
       "      <td>2014-12-05 15:56:33</td>\n",
       "      <td>o2i.univ-bpclermont.fr</td>\n",
       "      <td>2014-12-05 15:56:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr.yahoo.com</td>\n",
       "      <td>2014-11-04 10:03:19</td>\n",
       "      <td>yahoo.fr</td>\n",
       "      <td>2014-11-04 10:03:19</td>\n",
       "      <td>ocsp.verisign.com</td>\n",
       "      <td>2014-11-04 10:03:20</td>\n",
       "      <td>ocsp.thawte.com</td>\n",
       "      <td>2014-11-04 10:03:21</td>\n",
       "      <td>rapidssl-ocsp.geotrust.com</td>\n",
       "      <td>2014-11-04 10:03:21</td>\n",
       "      <td>clicks.beap.bc.yahoo.com</td>\n",
       "      <td>2014-11-04 10:03:22</td>\n",
       "      <td>ocsp.verisign.com</td>\n",
       "      <td>2014-11-04 10:03:22</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "      <td>2014-11-04 10:03:22</td>\n",
       "      <td>ocsp.digicert.com</td>\n",
       "      <td>2014-11-04 10:03:23</td>\n",
       "      <td>clicks.beap.bc.yahoo.com</td>\n",
       "      <td>2014-11-04 10:03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sci.sciences.univ-bpclermont.fr</td>\n",
       "      <td>2014-05-16 15:05:31</td>\n",
       "      <td>sci.sciences.univ-bpclermont.fr</td>\n",
       "      <td>2014-05-16 15:05:32</td>\n",
       "      <td>sci.sciences.univ-bpclermont.fr</td>\n",
       "      <td>2014-05-16 15:05:33</td>\n",
       "      <td>go.microsoft.com</td>\n",
       "      <td>2014-05-16 15:05:39</td>\n",
       "      <td>windows.microsoft.com</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>res2.windows.microsoft.com</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>res1.windows.microsoft.com</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>ajax.microsoft.com</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>js.microsoft.com</td>\n",
       "      <td>2014-05-16 15:05:40</td>\n",
       "      <td>www.bing.com</td>\n",
       "      <td>2014-05-16 15:05:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site1               time1  \\\n",
       "session_id                                                        \n",
       "1                          www.facebook.com 2014-10-04 11:19:53   \n",
       "2                            annotathon.org 2014-07-03 11:00:28   \n",
       "3             safebrowsing-cache.google.com 2014-12-05 15:55:12   \n",
       "4                              fr.yahoo.com 2014-11-04 10:03:19   \n",
       "5           sci.sciences.univ-bpclermont.fr 2014-05-16 15:05:31   \n",
       "\n",
       "                                      site2               time2  \\\n",
       "session_id                                                        \n",
       "1                  s-static.ak.facebook.com 2014-10-04 11:19:53   \n",
       "2                            annotathon.org 2014-07-03 11:00:53   \n",
       "3             safebrowsing-cache.google.com 2014-12-05 15:55:13   \n",
       "4                                  yahoo.fr 2014-11-04 10:03:19   \n",
       "5           sci.sciences.univ-bpclermont.fr 2014-05-16 15:05:32   \n",
       "\n",
       "                                      site3               time3  \\\n",
       "session_id                                                        \n",
       "1                           apis.google.com 2014-10-04 11:19:54   \n",
       "2                            annotathon.org 2014-07-03 11:00:58   \n",
       "3             safebrowsing-cache.google.com 2014-12-05 15:55:14   \n",
       "4                         ocsp.verisign.com 2014-11-04 10:03:20   \n",
       "5           sci.sciences.univ-bpclermont.fr 2014-05-16 15:05:33   \n",
       "\n",
       "                                    site4               time4  \\\n",
       "session_id                                                      \n",
       "1                           c1.adform.net 2014-10-04 11:19:54   \n",
       "2                          annotathon.org 2014-07-03 11:01:06   \n",
       "3           safebrowsing-cache.google.com 2014-12-05 15:56:15   \n",
       "4                         ocsp.thawte.com 2014-11-04 10:03:21   \n",
       "5                        go.microsoft.com 2014-05-16 15:05:39   \n",
       "\n",
       "                                    site5               time5  \\\n",
       "session_id                                                      \n",
       "1                          www.google.com 2014-10-04 11:19:54   \n",
       "2                          annotathon.org 2014-07-03 11:01:09   \n",
       "3           safebrowsing-cache.google.com 2014-12-05 15:56:16   \n",
       "4              rapidssl-ocsp.geotrust.com 2014-11-04 10:03:21   \n",
       "5                   windows.microsoft.com 2014-05-16 15:05:40   \n",
       "\n",
       "                                    site6               time6  \\\n",
       "session_id                                                      \n",
       "1                   mpp2.vindicosuite.com 2014-10-04 11:19:54   \n",
       "2                          annotathon.org 2014-07-03 11:01:10   \n",
       "3           safebrowsing-cache.google.com 2014-12-05 15:56:17   \n",
       "4                clicks.beap.bc.yahoo.com 2014-11-04 10:03:22   \n",
       "5              res2.windows.microsoft.com 2014-05-16 15:05:40   \n",
       "\n",
       "                                    site7               time7  \\\n",
       "session_id                                                      \n",
       "1                        api.nanigans.com 2014-10-04 11:19:54   \n",
       "2                          annotathon.org 2014-07-03 11:01:23   \n",
       "3           safebrowsing-cache.google.com 2014-12-05 15:56:18   \n",
       "4                       ocsp.verisign.com 2014-11-04 10:03:22   \n",
       "5              res1.windows.microsoft.com 2014-05-16 15:05:40   \n",
       "\n",
       "                                    site8               time8  \\\n",
       "session_id                                                      \n",
       "1                           www.google.fr 2014-10-04 11:19:54   \n",
       "2                          annotathon.org 2014-07-03 11:01:29   \n",
       "3           safebrowsing-cache.google.com 2014-12-05 15:56:19   \n",
       "4                       ocsp.digicert.com 2014-11-04 10:03:22   \n",
       "5                      ajax.microsoft.com 2014-05-16 15:05:40   \n",
       "\n",
       "                             site9               time9  \\\n",
       "session_id                                               \n",
       "1             secure.vistaprint.fr 2014-10-04 11:20:00   \n",
       "2                   annotathon.org 2014-07-03 11:01:30   \n",
       "3           o2i.univ-bpclermont.fr 2014-12-05 15:56:33   \n",
       "4                ocsp.digicert.com 2014-11-04 10:03:23   \n",
       "5                 js.microsoft.com 2014-05-16 15:05:40   \n",
       "\n",
       "                              site10              time10  \n",
       "session_id                                                \n",
       "1                  www.vistaprint.fr 2014-10-04 11:20:00  \n",
       "2                     annotathon.org 2014-07-03 11:01:53  \n",
       "3             o2i.univ-bpclermont.fr 2014-12-05 15:56:36  \n",
       "4           clicks.beap.bc.yahoo.com 2014-11-04 10:03:23  \n",
       "5                       www.bing.com 2014-05-16 15:05:44  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевую переменную и объединим выборки, чтобы вместе привести их к разреженному формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для самой первой модели будем использовать только посещенные сайты в сессии (но не будем обращать внимание на временные признаки). За таким выбором данных для модели стоит такая идея:  *у Элис есть свои излюбленные сайты, и чем чаще вы видим эти сайты в сессии, тем выше вероятность, что это сессия Элис и наоборот.*\n",
    "\n",
    "Подготовим данные, из всей таблицы выберем только признаки `site1, site2, ... , site10`. Напомним, что пропущенные значения заменены нулем. Вот как выглядят первые строки таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>safebrowsing.clients.google.com</td>\n",
       "      <td>safebrowsing-cache.google.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>javadl-esd-secure.oracle.com</td>\n",
       "      <td>www.caucho.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>www.caucho.com</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>www.webtide.com</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>download.oracle.com</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "      <td>jope.ow2.org</td>\n",
       "      <td>master.dl.sourceforge.net</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>download.eclipse.org</td>\n",
       "      <td>www.apache.org</td>\n",
       "      <td>public.dhe.ibm.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site1                          site2  \\\n",
       "session_id                                                                   \n",
       "21669       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                        www.apache.org                 www.apache.org   \n",
       "114021                      www.webtide.com            download.oracle.com   \n",
       "146670                   public.dhe.ibm.com                   jope.ow2.org   \n",
       "\n",
       "                                      site3                          site4  \\\n",
       "session_id                                                                   \n",
       "21669                                   NaN                            NaN   \n",
       "54843       safebrowsing.clients.google.com  safebrowsing-cache.google.com   \n",
       "77292                  download.eclipse.org                 www.apache.org   \n",
       "114021                       www.caucho.com            download.oracle.com   \n",
       "146670                  download.oracle.com             public.dhe.ibm.com   \n",
       "\n",
       "                      site5                      site6                site7  \\\n",
       "session_id                                                                    \n",
       "21669                   NaN                        NaN                  NaN   \n",
       "54843                   NaN                        NaN                  NaN   \n",
       "77292        www.apache.org            www.webtide.com  download.oracle.com   \n",
       "114021      www.webtide.com             www.apache.org   public.dhe.ibm.com   \n",
       "146670         jope.ow2.org  master.dl.sourceforge.net       www.apache.org   \n",
       "\n",
       "                                   site8           site9              site10  \n",
       "session_id                                                                    \n",
       "21669                                NaN             NaN                 NaN  \n",
       "54843                                NaN             NaN                 NaN  \n",
       "77292       javadl-esd-secure.oracle.com  www.caucho.com      www.apache.org  \n",
       "114021                   www.webtide.com  www.apache.org      www.apache.org  \n",
       "146670              download.eclipse.org  www.apache.org  public.dhe.ibm.com  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites = full_sites.fillna('0').astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сессии представляют собой последовательность индексов сайтов и данные в таком виде неудобны для линейных методов. В соответствии с нашей гипотезой (у Элис есть излюбленные сайты) надо преобразовать эту таблицу таким образом, чтобы каждому возможному сайту соответствовал свой отдельный признак (колонка), а его значение равнялось бы количеству посещений этого сайта в сессии. Это делается в две строчки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5396871a0cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvectorizer_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msite_title1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'site1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msite_title2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'site2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msite_title3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'site3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msite_title4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'site4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[0;32m    120\u001b[0m                              \"unicode string.\")\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "vectorizer_title = TfidfVectorizer(min_df=5, max_df=0.4, ngram_range=(1, 3))\n",
    "site_title1 = vectorizer_title.fit_transform(train_df['site1'])\n",
    "site_title2 = vectorizer_title.fit_transform(train_df['site2'])\n",
    "site_title3 = vectorizer_title.fit_transform(train_df['site3'])\n",
    "site_title4 = vectorizer_title.fit_transform(train_df['site4'])\n",
    "site_title5 = vectorizer_title.fit_transform(train_df['site5'])\n",
    "site_title6 = vectorizer_title.fit_transform(train_df['site6'])\n",
    "site_title7 = vectorizer_title.fit_transform(train_df['site7'])\n",
    "site_title8 = vectorizer_title.fit_transform(train_df['site8'])\n",
    "site_title9 = vectorizer_title.fit_transform(train_df['site9'])\n",
    "site_title10 = vectorizer_title.fit_transform(train_df['site10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_title.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один плюс использования разреженных матриц в том, что для них имеются специальные реализации как матричных операций, так и алгоритмов машинного обучения, что подчас позволяет ощутимо ускорить операции за счет особенностей структуры данных. Это касается и логистической регрессии. Вот теперь у нас все готово для построения нашей первой модели.\n",
    "\n",
    "### 2. Построение первой модели\n",
    "\n",
    "Итак, у нас есть алгоритм и данные для него, построим нашу первую модель, воспользовавшись релизацией [логистической регрессии](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из пакета `sklearn` с параметрами по умолчанию. Первые 90% данных будем использовать для обучения (обучающая выборка отсортирована по времени), а оставшиеся 10% для проверки качества (validation). \n",
    "\n",
    "**Напишите простую функцию, которая будет возвращать качество модели на отложенной выборке, и обучите наш первый классификатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    "    \n",
    "    # Ваш код здесь\n",
    "    train_len = int(ratio * X.shape[0])\n",
    "    X_train = X[:train_len, :]\n",
    "    X_valid = X[train_len:, :]\n",
    "    y_train = y[:train_len]\n",
    "    y_valid = y[train_len:]\n",
    "    \n",
    "    logit = LogisticRegression(C=C, n_jobs=1, random_state=seed)\n",
    "    logit.fit(X_train, y_train)\n",
    "    valid_pred = logit.predict_proba(X_valid)[:, 1]\n",
    "    return roc_auc_score(y_valid, valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрите, какой получился ROC AUC на отложенной выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9195264072196881"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X_train_sparse ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать эту модель нашей первой отправной точкой (baseline). Для построения модели для прогноза на тестовой выборке **необходимо обучить модель заново уже на всей обучающей выборке** (пока наша модель обучалась лишь на части данных), что повысит ее обобщающую способность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель на всей выборке, сделайте прогноз для тестовой выборки и сделайте посылку в соревновании**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pred = logit.predict_proba(X_test_sparse)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_df_pred, 'benchmark1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы выполните эти действия и загрузите ответ на [странице](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования, то воспроизведете первый бенчмарк \"Logit\".\n",
    "\n",
    "### 3. Улучшение модели, построение новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте такой признак, который будет представлять собой число вида ГГГГММ от той даты, когда проходила сессия, например 201407 -- 2014 год и 7 месяц. Таким образом, мы будем учитывать помесячный [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь период предоставленных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train = pd.DataFrame(index=train_df.index)\n",
    "new_feat_test = pd.DataFrame(index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "new_feat_train['year_month'] = train_df['time1'].apply(lambda t: t.year * 100 + t.month)\n",
    "new_feat_test['year_month'] = test_df['time1'].apply(lambda t: t.year * 100 + t.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте новый признак, предварительно отмасштабировав его с помощью `StandardScaler`, и снова посчитайте ROC AUC на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_feat_train['year_month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "new_feat_train['year_month'] = scaler.transform(new_feat_train['year_month'].values.reshape(-1,1))\n",
    "new_feat_test['year_month'] = scaler.transform(new_feat_test['year_month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_month\n",
       "session_id            \n",
       "21669        -1.744405\n",
       "54843        -1.744405\n",
       "77292        -1.744405\n",
       "114021       -1.744405\n",
       "146670       -1.744405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = csr_matrix(hstack([X_train_sparse, \n",
    "                         new_feat_train['year_month'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = csr_matrix(hstack([X_test_sparse, \n",
    "                         new_feat_test['year_month'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48372), (82797, 48372))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9196941166738521"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте два новых признака: start_hour и morning.**\n",
    "\n",
    "Признак `start_hour` – это час в который началась сессия (от 0 до 23), а бинарный признак `morning` равен 1, если сессия началась утром и 0, если сессия началась позже (будем считать, что утро это если `start_hour равен` 11 или меньше).\n",
    "\n",
    "**Посчитйте ROC AUC на отложенной выборке для выборки с:**\n",
    "- сайтами, `start_month` и `start_hour`\n",
    "- сайтами, `start_month` и `morning`\n",
    "- сайтами, `start_month`, `start_hour` и `morning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "new_feat_train['start_hour'] = train_df['time1'].apply(lambda t: t.hour)\n",
    "new_feat_train['morning'] = new_feat_train['start_hour'].apply(lambda t: 1 if((t < 12)&(t >= 6)) else 0)\n",
    "new_feat_train['day'] = new_feat_train['start_hour'].apply(lambda t: 1 if((t < 18)&(t >= 12)) else 0)\n",
    "new_feat_train['evening'] = new_feat_train['start_hour'].apply(lambda t: 1 if((t <= 23)&(t >= 18)) else 0)\n",
    "new_feat_train['night'] = new_feat_train['start_hour'].apply(lambda t: 1 if((t < 6)&(t >= 0)) else 0)\n",
    "new_feat_train['weekday'] = train_df['time1'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_test['start_hour'] = test_df['time1'].apply(lambda t: t.hour)\n",
    "new_feat_test['morning'] = new_feat_test['start_hour'].apply(lambda t: 1 if((t < 12)&(t >= 6)) else 0)\n",
    "new_feat_test['day'] = new_feat_test['start_hour'].apply(lambda t: 1 if((t < 18)&(t >= 12)) else 0)\n",
    "new_feat_test['evening'] = new_feat_test['start_hour'].apply(lambda t: 1 if((t <= 23)&(t >= 18)) else 0)\n",
    "new_feat_test['night'] = new_feat_test['start_hour'].apply(lambda t: 1 if((t < 6)&(t >= 0)) else 0)\n",
    "new_feat_test['weekday'] = test_df['time1'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(new_feat_train['start_hour'].values.reshape(-1,1))\n",
    "scaler.fit(new_feat_train['weekday'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "new_feat_train['start_hour'] = scaler.transform(new_feat_train['start_hour'].values.reshape(-1,1))\n",
    "new_feat_test['start_hour'] = scaler.transform(new_feat_test['start_hour'].values.reshape(-1,1))\n",
    "new_feat_train['weekday'] = scaler.transform(new_feat_train['weekday'].values.reshape(-1,1))\n",
    "new_feat_test['weekday'] = scaler.transform(new_feat_test['weekday'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>-1.744405</td>\n",
       "      <td>3.545722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>-1.744405</td>\n",
       "      <td>3.545722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>-1.744405</td>\n",
       "      <td>3.545722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>-1.744405</td>\n",
       "      <td>3.545722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>-1.744405</td>\n",
       "      <td>3.545722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_month  start_hour  morning  day  evening  night   weekday\n",
       "session_id                                                                \n",
       "21669        -1.744405    3.545722        1    0        0      0  1.682905\n",
       "54843        -1.744405    3.545722        1    0        0      0  1.682905\n",
       "77292        -1.744405    3.545722        1    0        0      0  1.682905\n",
       "114021       -1.744405    3.545722        1    0        0      0  1.682905\n",
       "146670       -1.744405    3.545722        1    0        0      0  1.682905"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_title = TfidfVectorizer(min_df=3, max_df=0.3, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_1 = csr_matrix(hstack([X_train_sparse, \n",
    "                         new_feat_train['start_hour'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse_1 = csr_matrix(hstack([X_test_sparse, \n",
    "                         new_feat_test['start_hour'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48373), (82797, 48373))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_1.shape, X_test_sparse_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579184373524429"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_2 = csr_matrix(hstack([X_train_sparse, \n",
    "                         new_feat_train['morning'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse_2 = csr_matrix(hstack([X_test_sparse, \n",
    "                         new_feat_test['morning'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48373), (82797, 48373))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_2.shape, X_test_sparse_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486670947710878"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_3 = csr_matrix(hstack([X_train_sparse_1, \n",
    "                         new_feat_train['morning'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse_3 = csr_matrix(hstack([X_test_sparse_1, \n",
    "                         new_feat_test['morning'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48374), (82797, 48374))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_3.shape, X_test_sparse_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959119424226725"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_4 = csr_matrix(hstack([\n",
    "    X_train_sparse_1,\n",
    "    new_feat_train['morning'].values.reshape(-1, 1),\n",
    "    new_feat_train['day'].values.reshape(-1, 1),\n",
    "    new_feat_train['evening'].values.reshape(-1, 1),\n",
    "    new_feat_train['night'].values.reshape(-1, 1)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse_4 = csr_matrix(hstack([\n",
    "    X_test_sparse_1,\n",
    "    new_feat_test['morning'].values.reshape(-1, 1),\n",
    "    new_feat_test['day'].values.reshape(-1, 1),\n",
    "    new_feat_test['evening'].values.reshape(-1, 1),\n",
    "    new_feat_test['night'].values.reshape(-1, 1)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48377), (82797, 48377))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_4.shape, X_test_sparse_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629577215183759"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_5 = csr_matrix(hstack([\n",
    "    X_train_sparse_4,\n",
    "    new_feat_train['weekday'].values.reshape(-1, 1),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse_5 = csr_matrix(hstack([\n",
    "    X_test_sparse_4,\n",
    "    new_feat_test['weekday'].values.reshape(-1, 1),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48378), (82797, 48378))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_5.shape, X_test_sparse_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718308498446385"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_5, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "записываем результаты бенчмарка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=17, C=0.06)\n",
    "logit.fit(X_train_sparse_5, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pred = logit.predict_proba(X_test_sparse_5)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_df_pred, 'benchmark3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Подбор коэффицициента регуляризации\n",
    "\n",
    "Итак, мы ввели признаки, которые улучшают качество нашей модели по сравнению с первым бейслайном. Можем ли мы добиться большего значения метрики? После того, как мы сформировали обучающую и тестовую выборки, почти всегда имеет смысл подобрать оптимальные гиперпараметры -- характеристики модели, которые не изменяются во время обучения. Например, на 3 неделе вы проходили решающие деревья, глубина дерева это гиперпараметр, а признак, по которому происходит ветвление и его значение -- нет. В используемой нами логистической регрессии веса каждого признака изменяются и во время обучения находится их оптимальные значения, а коэффициент регуляризации остается постоянным. Это тот гиперпараметр, который мы сейчас будем оптимизировать.\n",
    "\n",
    "Посчитайте качество на отложенной выборке с коэффициентом регуляризации, который по умолчанию `C=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718308498446385"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "get_auc_lr_valid(X_train_sparse_5, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постараемся побить этот результат за счет оптимизации коэффициента регуляризации. Возьмем набор возможных значений C и для каждого из них посчитаем значение метрики на отложенной выборке.\n",
    "\n",
    "Найдите `C` из `np.logspace(-3, 1, 10)`, при котором ROC AUC на отложенной выборке максимален. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001 0.8833818498216937\n",
      "C = 0.0027825594022071257 0.9416671497181999\n",
      "C = 0.007742636826811269 0.9671612510551657\n",
      "C = 0.021544346900318832 0.9753139533058236\n",
      "C = 0.05994842503189409 0.977111357869936\n",
      "C = 0.1668100537200059 0.9761236684382582\n",
      "C = 0.46415888336127775 0.9739437474413364\n",
      "C = 1.2915496650148828 0.9709442993277131\n",
      "C = 3.593813663804626 0.9661376346657102\n",
      "C = 10.0 0.9598575118740105\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "for i in np.logspace(-3, 1, 10):\n",
    "    print('C =', i, get_auc_lr_valid(X_train_sparse_5, y_train, C=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.06 0.9771118107307483\n",
      "C = 0.061 0.9771170941068921\n",
      "C = 0.062 0.9771205660397866\n",
      "C = 0.063 0.9771189055501414\n",
      "C = 0.064 0.9771192074573495\n",
      "C = 0.065 0.9771222265294317\n",
      "C = 0.066 0.9771189055501414\n",
      "C = 0.067 0.9771238870190769\n",
      "C = 0.068 0.9771213208078071\n",
      "C = 0.069 0.9771176979213085\n",
      "C = 0.07 0.9771018477928771\n"
     ]
    }
   ],
   "source": [
    "arr = {}\n",
    "for i in np.arange(0.05, 0.07, 0.001):\n",
    "    print('C =', i, get_auc_lr_valid(X_train_sparse_5, y_train, C=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771018477928771"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_5, y_train, C=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обучите модель с найденным оптимальным значением коэффициента регуляризации и с построенными признаками `start_hour`, `start_month` и `morning`. Если вы все сделали правильно и загрузите это решение, то повторите второй бенчмарк соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
